{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv3T0M8-MCMB",
        "outputId": "fe218bdb-0519-46ad-8519-86f9cd67604a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foBdXEF0MwEQ"
      },
      "source": [
        "lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "XmQF7il4Q7AR"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install roboflow inference supervision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "D6lCwlioSFXT"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "O0NHH_LjBrZj"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pytesseract\n",
        "!sudo apt-get install tesseract-ocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "0kHZiXpfR46s"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import cv2 as cv\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "from tensorflow.keras.models import load_model\n",
        "from roboflow import Roboflow\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "from pytesseract import image_to_string\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "_fIsiBRpMM6q"
      },
      "outputs": [],
      "source": [
        "def len_video_from_dir(dir):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "      dir: Source video directory\n",
        "    Raises:\n",
        "      Exception: File not found\n",
        "      Exception: Video corrupted or of invalid format\n",
        "    Returns: len of video\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(dir):\n",
        "        raise Exception(\"File not found\")\n",
        "\n",
        "    video_capture = cv.VideoCapture(dir)\n",
        "    if not video_capture.isOpened():\n",
        "        raise Exception(\"Could not open video\")\n",
        "\n",
        "    return int(video_capture.get(cv.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "\n",
        "import os\n",
        "import cv2 as cv\n",
        "\n",
        "def save_frame(video_dir, frame_num, output_dir, output_filename):\n",
        "    \"\"\"\n",
        "    Saves the extracted frame as an image file in the specified directory.\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(video_dir):\n",
        "        raise Exception(\"File not found\")\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    video_capture = cv.VideoCapture(video_dir)\n",
        "    if not video_capture.isOpened():\n",
        "        raise Exception(\"Could not open video\")\n",
        "\n",
        "    video_capture.set(cv.CAP_PROP_POS_FRAMES, frame_num)\n",
        "\n",
        "    # Check the actual frame position\n",
        "    current_frame = int(video_capture.get(cv.CAP_PROP_POS_FRAMES))\n",
        "    if current_frame != frame_num:\n",
        "        raise Exception(f\"Frame {frame_num} not found, at {current_frame} instead\")\n",
        "\n",
        "    success, frame = video_capture.read()\n",
        "    if not success or frame is None:\n",
        "        raise Exception(f\"Could not retrieve the frame {frame_num}\")\n",
        "\n",
        "    # Optionally, check for frame integrity\n",
        "    if frame.shape[0] == 0 or frame.shape[1] == 0:\n",
        "        raise Exception(\"Frame data is empty or corrupted\")\n",
        "\n",
        "    # Save the original frame without conversion (BGR format)\n",
        "    output_path = os.path.join(output_dir, output_filename)\n",
        "    cv.imwrite(output_path, frame)\n",
        "\n",
        "    # Release video capture\n",
        "    video_capture.release()\n",
        "\n",
        "def crop_imgs_from_predicition(pred, img):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "      pred: Roboflow prediction json\n",
        "      img: Image to be cropped\n",
        "    Returns: List of cropped images from predictions or None if no images were cropped\n",
        "    \"\"\"\n",
        "    pred = pred[\"predictions\"]\n",
        "    imgs = []\n",
        "    for p in pred:\n",
        "        h = int(math.floor(p[\"height\"]))\n",
        "        w = int(math.floor(p[\"width\"]))\n",
        "        py = (int(p[\"y\"]) - (h // 2), int(p[\"y\"]) + (h // 2))\n",
        "        px = (int(p[\"x\"]) - (w // 2), int(p[\"x\"]) + (w // 2))\n",
        "        imgs.append(img[py[0]:py[1], px[0]:px[1]])\n",
        "    return imgs if len(imgs) != 0 else None\n",
        "\n",
        "def load_and_predict(input_data, model_head, model_eyes):\n",
        "  \"\"\"Loads two models and returns the prediction of the last one.\n",
        "\n",
        "  Args:\n",
        "    model_head_path: Path para o modelo de cabeça.\n",
        "    model_eyes_path: Path para o modelo dos olhos.\n",
        "    input_data: Array de imagem contexto X.\n",
        "\n",
        "  Returns:\n",
        "    Predição do modelo de olhos.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    # Predição da cabeça\n",
        "    prediction_head = model_head.predict(input_data)\n",
        "\n",
        "    # Aplicando mascara de segmentação da cabeça\n",
        "    data_x = prediction_head * input_data\n",
        "\n",
        "    # Predição dos olhos\n",
        "    prediction_eye = model_eyes.predict(data_x)\n",
        "\n",
        "    # Retorna segmentação dos olhos\n",
        "    return prediction_eye\n",
        "  except Exception as e:\n",
        "    print(f\"Erro carregando os modelos: {e}\")\n",
        "    raise\n",
        "    return None\n",
        "\n",
        "\n",
        "def only_eyes(image_original,image_predita):\n",
        "  \"\"\"\n",
        "    Parameters:\n",
        "      image_original: Contexto  X image 128x128\n",
        "      image_predita: output do modelo de sementação dos olhos image 128x128\n",
        "    Returns: Imagem original com área preta fora dos olhos\n",
        "    \"\"\"\n",
        "  img1 = image_predita\n",
        "  img2 = image_original\n",
        "  mask = img1 > 0.5 #seleciono apenas os pixeis que não são pretos na imagem predita\n",
        "  img2_eyes = np.zeros_like(img2) #crio uma imagem vazia com as mesmas dimensões da imagem original\n",
        "\n",
        "  img2_eyes[mask] = img2[mask]# faço a máscara dos olhos na imagem original\n",
        "\n",
        "  return img2_eyes\n",
        "\n",
        "def get_temp_from_pixel(pixel, temp_tuple):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "      pix: rgb color tuple representing image pixel\n",
        "      temp_tuple: (min, max) temperature tuple representing the temperature scale\n",
        "    Returns: °C tempertature from pixel\n",
        "    \"\"\"\n",
        "    MIN_TEMP_PIXEL = 32 / 255.0\n",
        "    MAX_TEMP_PIXEL = 159 / 255.0\n",
        "    TEMP_PIXEL_RANGE = MAX_TEMP_PIXEL - MIN_TEMP_PIXEL\n",
        "\n",
        "    if pixel < MIN_TEMP_PIXEL: pixel = MIN_TEMP_PIXEL\n",
        "    if pixel > MAX_TEMP_PIXEL: pixel = MAX_TEMP_PIXEL\n",
        "\n",
        "    min_temp = min(temp_tuple)\n",
        "    max_temp = max(temp_tuple)\n",
        "    temp_range = max_temp - min_temp\n",
        "\n",
        "    temp = min_temp + ((pixel - MIN_TEMP_PIXEL) / TEMP_PIXEL_RANGE) * temp_range\n",
        "\n",
        "    return temp\n",
        "\n",
        "\n",
        "def get_temp_olhos(image_original,image_predita, temp_tupla):\n",
        "  \"\"\"\n",
        "    Parameters:\n",
        "      image_original: Contexto  X image 128x128\n",
        "      image_predita: output do modelo de sementação dos olhos image 128x128\n",
        "      temp_tuple: (min, max) tupla de temperatura representando o intervalo de temperatura\n",
        "    Returns: °C tempertatura dos olhos bovinos\n",
        "    \"\"\"\n",
        "  if temp_tupla[0] == None or temp_tupla[1] == None:\n",
        "    return None\n",
        "  img = only_eyes(image_original,image_predita)\n",
        "  img_ble = img[img > 0.1]\n",
        "  media = np.mean(img_ble)\n",
        "  return get_temp_from_pixel(media, temp_tupla)\n",
        "\n",
        "def draw_temp(image_original, temp):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "      image_original: Imagem original no formato np.array\n",
        "      temp: Temperatura que será desenhada na imagem\n",
        "    Returns:\n",
        "      Exibe a imagem com a temperatura desenhada no canto superior esquerdo\n",
        "    \"\"\"\n",
        "    im = Image.fromarray(image_original.astype(np.uint8))\n",
        "    draw = ImageDraw.Draw(im)\n",
        "\n",
        "    temp_text = f\"{temp:.1f}°C\"\n",
        "    draw.text((20, 20), temp_text, fill=\"red\")\n",
        "    im.show()\n",
        "\n",
        "get_resized_img = lambda img: cv.resize(img, (128, 128), interpolation=cv.INTER_LINEAR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEtHsxBwNaoy"
      },
      "source": [
        "Pegar vídeo -> Selecionar os frames -> Realizar object detection nos frames para extrair o X -> Recortar o X -> Realizar a segmentação da cabeça e dos olhos -> Medir a temperatura de cada olho"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUC4dlj4Rnxz"
      },
      "source": [
        "# Object Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "6GQARFMfQtkD"
      },
      "outputs": [],
      "source": [
        "def save_predictions_to_df(predictions_list):\n",
        "    # Lista para armazenar todas as previsões\n",
        "    all_predictions = []\n",
        "\n",
        "    # Iterar por cada conjunto de previsões\n",
        "    for prediction_set in predictions_list:\n",
        "        # Extrair as previsões de cada imagem\n",
        "        for prediction in prediction_set['predictions']:\n",
        "            # Adicionar ao conjunto de todas as previsões\n",
        "            all_predictions.append(prediction)\n",
        "\n",
        "    # Criar o DataFrame a partir das previsões consolidadas\n",
        "    df = pd.DataFrame(all_predictions)\n",
        "\n",
        "    return df\n",
        "\n",
        "def find_cattle(image_folder_path):\n",
        "  \"\"\"\n",
        "  Retorna uma lista de jsons\n",
        "  \"\"\"\n",
        "  image_files = []\n",
        "  for filename in os.listdir(image_folder_path):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "        image_files.append(os.path.join(image_folder_path, filename))\n",
        "\n",
        "  predictions = []\n",
        "  rf = Roboflow(api_key=\"P0Tl1nhUD7sHjcWmQCvs\")\n",
        "  project = rf.workspace().project(\"bois-teste-samuel\")\n",
        "  model = project.version(1).model\n",
        "\n",
        "  for i in range(len(image_files)):\n",
        "      prediction = model.predict(image_files[i], confidence=45, overlap=30).json()\n",
        "      predictions.append(prediction)\n",
        "  return [save_predictions_to_df(predictions), predictions]\n",
        "\n",
        "def draw_box(img, x, y, width, height, label, confidence, color=(0, 255, 0), text_color=(255, 255, 255), thickness=2, text_box_height_increase=10):\n",
        "    # Calcular as coordenadas dos vértices da caixa\n",
        "    x1 = int(x - width / 2)\n",
        "    y1 = int(y - height / 2)\n",
        "    x2 = int(x + width / 2)\n",
        "    y2 = int(y + height / 2)\n",
        "\n",
        "    # Desenhar o retângulo da caixa\n",
        "    cv.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
        "\n",
        "    # Texto com o rótulo e a confiança (convertido para porcentagem)\n",
        "    label_text = f'{label}: {confidence * 100:.2f}%'\n",
        "\n",
        "    # Medir o tamanho do texto para desenhar o fundo corretamente\n",
        "    (text_width, text_height), baseline = cv.getTextSize(label_text, cv.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
        "\n",
        "    # Aumentar a altura do fundo do texto\n",
        "    total_text_height = text_height + baseline + text_box_height_increase\n",
        "\n",
        "    # Desenhar o retângulo de fundo do texto com altura aumentada\n",
        "    cv.rectangle(img, (x1, y1 - total_text_height - 5), (x1 + text_width, y1), color, -1)\n",
        "\n",
        "    # Colocar o texto sobre o fundo\n",
        "    cv.putText(img, label_text, (x1, y1 - baseline - 5), cv.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 2)\n",
        "\n",
        "def plot_all_cattle_predictions(cattle_predictions):\n",
        "  for i in range(len(cattle_predictions)):\n",
        "    # Verifica se 'predictions' existe no dicionário e se não está vazio\n",
        "    if 'predictions' in cattle_predictions[i] and cattle_predictions[i]['predictions']:\n",
        "        # Obtenha o caminho da imagem a partir da primeira predição\n",
        "        image_path = cattle_predictions[i]['predictions'][0].get('image_path')\n",
        "\n",
        "        # Verifica se o caminho da imagem não é nulo ou vazio\n",
        "        if image_path:\n",
        "            # Ler a imagem uma vez por loop\n",
        "            img = cv.imread(image_path)\n",
        "\n",
        "            if img is not None:\n",
        "                # Para cada predição da imagem, desenha a caixa\n",
        "                for prediction in cattle_predictions[i].get('predictions', []):\n",
        "                    x = prediction.get('x')\n",
        "                    y = prediction.get('y')\n",
        "                    width = prediction.get('width')\n",
        "                    height = prediction.get('height')\n",
        "                    label = prediction.get('class')\n",
        "                    confidence = prediction.get('confidence')\n",
        "                    draw_box(img, x, y, width, height, \"boi\", confidence)  # Desenhar a caixa na imagem\n",
        "\n",
        "                # Exibe a imagem com todas as caixas desenhadas\n",
        "                plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))  # Converter BGR para RGB\n",
        "                plt.axis('off')  # Remover os eixos\n",
        "                plt.show()  # Mostrar a imagem com todas as caixas desenhadas\n",
        "            else:\n",
        "                print(f\"Erro ao carregar a imagem no caminho: {image_path}\")\n",
        "        else:\n",
        "            print(\"Caminho da imagem está vazio.\")\n",
        "    else:\n",
        "        print(f\"Nenhuma predição encontrada para a imagem {i}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "90tAlaGC_QSI"
      },
      "outputs": [],
      "source": [
        "def get_global_temp(frame):\n",
        "\n",
        "  def type_convert(img, silent=False):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "      img: np.array of image\n",
        "    Raises:\n",
        "      Exception: If image couldn't be converted to np.array\n",
        "    Returns: Normalized image np.array\n",
        "    \"\"\"\n",
        "    img = deepcopy(img)\n",
        "    if not isinstance(img, np.ndarray):\n",
        "      try: img = np.array(img)\n",
        "      except Exception: raise Exception(f'Could not convert {type(np.array(None))} to np.array')\n",
        "    if not silent: print(\"--- Warning: Image is now a normalized np.array ---\")\n",
        "    return img / 255.0 if type(img.flatten()[0]) not in (np.float16, np.float32, np.float64, np.float128) else img\n",
        "\n",
        "  def check_dims_number(img):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "      img: np.array of image\n",
        "    Raises:\n",
        "      Exception: If image doesn't have 3 channels\n",
        "    \"\"\"\n",
        "    if len(img.shape) != 3: raise Exception(f'Array must have three channels, got {img.shape}')\n",
        "\n",
        "  def get_digits(img, silent=False):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "      img: np.array of image\n",
        "      silent: If it should be verbose on image conversion\n",
        "    Raises:\n",
        "      Exception: If image doesn't have 3 channels\n",
        "      Exception: If image couldn't be converted to np.array\n",
        "    Returns: Tuple of cut digits from image (shape (2, 4, img_channels))\n",
        "    \"\"\"\n",
        "    img = deepcopy(img)\n",
        "\n",
        "    def preprocess(img):\n",
        "      \"\"\"\n",
        "      Parameters:\n",
        "        img: np.array of image\n",
        "      Raises:\n",
        "        Exception: If image doesn't have 3 channels\n",
        "        Exception: If image couldn't be converted to np.array\n",
        "      Returns: Preprocessed image for getting digits\n",
        "      \"\"\"\n",
        "      img = type_convert(img, silent)\n",
        "      check_dims_number(img)\n",
        "      if img.shape[:2] != (512, 640): return cv.resize(img, (640, 512), interpolation=cv.INTER_LINEAR)\n",
        "      return img\n",
        "\n",
        "    img = preprocess(img)\n",
        "\n",
        "    BOTTOM_DIGITS_LOCATION = [\n",
        "      (403, 511, 425, 527),\n",
        "      (403, 527, 425, 543),\n",
        "      (403, 543, 425, 559),\n",
        "      (403, 559, 425, 575)\n",
        "    ]\n",
        "\n",
        "    TOP_DIGITS_LOCATION = [\n",
        "      (67, 511, 89, 527),\n",
        "      (67, 527, 89, 543),\n",
        "      (67, 543, 89, 559),\n",
        "      (67, 559, 89, 575)\n",
        "    ]\n",
        "\n",
        "\n",
        "    return tuple([\n",
        "      tuple(img[y1:y2, x1:x2] for (y1, x1, y2, x2) in BOTTOM_DIGITS_LOCATION),\n",
        "      tuple(img[y1:y2, x1:x2] for (y1, x1, y2, x2) in TOP_DIGITS_LOCATION)\n",
        "    ])\n",
        "\n",
        "  def get_bw_imgs(img, silent=False):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "      img: Image to be optimized\n",
        "    Raises:\n",
        "      Exception: If image doesn't have 3 channels\n",
        "      Exception: If image couldn't be converted to np.array\n",
        "    Returns: String converted in black and white versions without background\n",
        "    \"\"\"\n",
        "    img = deepcopy(img)\n",
        "\n",
        "    img = type_convert(img, silent)\n",
        "    check_dims_number(img)\n",
        "\n",
        "    THRESHOLD = (15 / 255.0, 180 / 255.0)\n",
        "\n",
        "    img_b = np.zeros(img.shape, np.float32)\n",
        "    img_w = np.zeros(img.shape, np.float32)\n",
        "\n",
        "\n",
        "    for y in range(img.shape[0]):\n",
        "      for x in range(img.shape[1]):\n",
        "        pix = img[y, x][0]\n",
        "        if pix <= THRESHOLD[0]:  img_b[y, x] = [1., 1., 1.]\n",
        "        if pix >= THRESHOLD[1]: img_w[y, x] = [1., 1., 1.]\n",
        "\n",
        "    return tuple([img_b, img_w])\n",
        "\n",
        "  def to_str(img):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "      img: Image to be converted to string (Optimized for numbers)\n",
        "    Returns: String converted from image (No whitespaces)\n",
        "    \"\"\"\n",
        "    preprocess = lambda img: cv.GaussianBlur(\n",
        "      cv.erode((img * 255).astype(np.uint8), np.ones((2, 2), np.uint8), iterations=1),\n",
        "      (3, 3),\n",
        "      .2\n",
        "    )\n",
        "\n",
        "    return image_to_string(preprocess(img), config='--psm 6').replace(' ', '')\n",
        "\n",
        "  def get_temp_from_img_pixel(img, location, temp_tuple, silent=True):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "      img: np.array of image\n",
        "      location: (y, x) location tuple of pixel\n",
        "      temp_tuple: (min, max) temperature tuple representing the temperature scale\n",
        "      silent: If it should be verbose on image conversion\n",
        "    Raises:\n",
        "      Exception: Out of bounds location\n",
        "      Exception: If image couldn't be converted to np.array\n",
        "    Returns: °C tempertature from image in pixel\n",
        "    \"\"\"\n",
        "    def get_temp_from_pixel(pixel, temp_tuple):\n",
        "      \"\"\"\n",
        "      Parameters:\n",
        "        pix: rgb color tuple representing image pixel\n",
        "        temp_tuple: (min, max) temperature tuple representing the temperature scale\n",
        "      Returns: °C tempertature from pixel\n",
        "      \"\"\"\n",
        "      MIN_TEMP_PIXEL = 32 / 255.0\n",
        "      MAX_TEMP_PIXEL = 159 / 255.0\n",
        "      TEMP_PIXEL_RANGE = MAX_TEMP_PIXEL - MIN_TEMP_PIXEL\n",
        "\n",
        "      pixel = pixel[0]\n",
        "      if pixel < MIN_TEMP_PIXEL: pixel = MIN_TEMP_PIXEL\n",
        "      if pixel > MAX_TEMP_PIXEL: pixel = MAX_TEMP_PIXEL\n",
        "\n",
        "      min_temp = min(temp_tuple)\n",
        "      max_temp = max(temp_tuple)\n",
        "      temp_range = max_temp - min_temp\n",
        "\n",
        "      temp = min_temp + ((pixel - MIN_TEMP_PIXEL) / TEMP_PIXEL_RANGE) * temp_range\n",
        "\n",
        "      return temp\n",
        "\n",
        "    img = type_convert(img, silent)\n",
        "    check_dims_number(img)\n",
        "\n",
        "    try: pixel = img[location]\n",
        "    except Exception: raise Exception(f'Out of bounds for image shape {img.shape}, {location} is not acceptible')\n",
        "    return get_temp_from_pixel(pixel, temp_tuple)\n",
        "\n",
        "  digits = [i for i in get_digits(frame, silent=True)]\n",
        "\n",
        "  imgs = [None, None]\n",
        "  for idx, tup in enumerate(digits):\n",
        "    for jdx, im in enumerate(tup):\n",
        "      for i in get_bw_imgs(im, silent=True):\n",
        "        if imgs[idx] is None: imgs[idx] = i\n",
        "        else: imgs[idx] = np.hstack((imgs[idx], i))\n",
        "\n",
        "  for i in range(len(imgs)):\n",
        "    imgs[i] = to_str(imgs[i])\n",
        "\n",
        "  imgs = (''.join([i for i in imgs[0] if i.isdigit() or i in ['-', '.']]), ''.join([i for i in imgs[1] if i.isdigit() or i in ['-', '.']]))\n",
        "  try:\n",
        "    imgs = (float(imgs[0]), float(imgs[1]))\n",
        "  except:\n",
        "    imgs = (None, None)\n",
        "\n",
        "  return tuple(imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "AIGwIRfMd7ju"
      },
      "outputs": [],
      "source": [
        "def save_multiple_frames(video_path, save_dir, division_factor):\n",
        "  # prompt: Delete all the files inside save_dir\n",
        "  # delete all the files inside save_dir\n",
        "  for filename in os.listdir(save_dir):\n",
        "      file_path = os.path.join(save_dir, filename)\n",
        "      try:\n",
        "          if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "              os.unlink(file_path)\n",
        "              # elif os.path.isdir(file_path):\n",
        "          #     shutil.rmtree(file_path)\n",
        "      except Exception as e:\n",
        "          print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "  frame_count = len_video_from_dir(video_path)\n",
        "  for i in range(0, frame_count, division_factor):\n",
        "      save_frame(video_path, i, frames_folder_path, f\"frame_{i}.jpg\")\n",
        "\n",
        "def crop_all_images(X_folder_path, predictions_json):\n",
        "\n",
        "  # Limpa o repositório\n",
        "  for filename in os.listdir(X_folder_path):\n",
        "      file_path = os.path.join(X_folder_path, filename)\n",
        "      try:\n",
        "          if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "              os.unlink(file_path)\n",
        "              # elif os.path.isdir(file_path):\n",
        "          #     shutil.rmtree(file_path)\n",
        "      except Exception as e:\n",
        "          print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "  for prediction in predictions_json:\n",
        "    if len(prediction[\"predictions\"]) == 0:\n",
        "      continue\n",
        "    cropped_images = crop_imgs_from_predicition(prediction, cv.imread(prediction[\"predictions\"][0][\"image_path\"]))\n",
        "    frame_path = prediction[\"predictions\"][0][\"image_path\"]\n",
        "    frame_name = os.path.basename(frame_path)\n",
        "    frame_name_without_extension = os.path.splitext(frame_name)[0]\n",
        "    for i, cropped_image in enumerate(cropped_images):\n",
        "      file_name = f\"{frame_name_without_extension}_X_{i}.jpg\"\n",
        "      output_path = os.path.join(X_folder_path, file_name)\n",
        "      cv.imwrite(output_path, cv.cvtColor(cropped_image, cv.COLOR_RGB2BGR))\n",
        "\n",
        "def segment_eyes_and_get_temperatures(frames_folder_path, X_folder_path, y_folder_path, model_head_path, model_eyes_path):\n",
        "\n",
        "  model_head = load_model(model_head_path, compile=False) # Exemplo Path: '/content/drive/MyDrive/CattleImageRepository/G2/segmentacao_cabeca.keras'\n",
        "  model_eyes = load_model(model_eyes_path, compile=False)\n",
        "  images = []\n",
        "  y_names = []\n",
        "  # iterate over files in X_folder_path\n",
        "  for filename in os.listdir(X_folder_path):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "      # load image\n",
        "      img = cv.imread(os.path.join(X_folder_path, filename))\n",
        "      img = get_resized_img(img)\n",
        "      img = img / 255.0\n",
        "      images.append(img)\n",
        "      y_names.append(f\"{filename[:-4]}_y.jpg\")\n",
        "\n",
        "  batched_images = np.stack(images, axis=0)\n",
        "  prediction_list = load_and_predict(batched_images, model_head, model_eyes)\n",
        "\n",
        "  eye_temperatures = []\n",
        "\n",
        "  for i in range(len(y_names)):\n",
        "    frame_name = y_names[i].split(\"_X_\")[0]\n",
        "    frame = cv.imread(os.path.join(frames_folder_path, f\"{frame_name}.jpg\"))\n",
        "    temperature_tuple = get_global_temp(frame)\n",
        "    X_name = y_names[i].replace(\"_y\", \"\")\n",
        "    X = cv.imread(os.path.join(X_folder_path, X_name))\n",
        "    X = get_resized_img(X)\n",
        "    eye_temperature = get_temp_olhos(X, prediction_list[i], temperature_tuple, 90)\n",
        "    eye_temperatures.append(eye_temperature)\n",
        "\n",
        "  return eye_temperatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "collapsed": true,
        "id": "u_yqgMVpShk2"
      },
      "outputs": [],
      "source": [
        "def final_function(path):\n",
        "  video_path = \"/content/drive/MyDrive/videos/00000000220000000.mp4\"\n",
        "  video_path = path\n",
        "  frames_folder_path = \"/content/drive/MyDrive/modelo_final/frames_from_video_temp_folder\"\n",
        "  X_folder_path = \"/content/drive/MyDrive/modelo_final/X_temp_folder\"\n",
        "  y_folder_path = \"/content/drive/MyDrive/modelo_final/y_temp_folder\"\n",
        "  model_head_path = '/content/drive/MyDrive/CattleImageRepository/G2/segmentacao_cabeca.keras'\n",
        "  model_eyes_path = '/content/drive/MyDrive/CattleImageRepository/G2/modelo_olho.keras'\n",
        "  frame_interval = 200\n",
        "\n",
        "  # Comentar a linha abaixo quando não for a primeira vez rodando o código para esse vídeo\n",
        "  save_multiple_frames(video_path, frames_folder_path, frame_interval)\n",
        "  df_and_json = find_cattle(frames_folder_path)\n",
        "  cattle_predictions = df_and_json[0]\n",
        "  # Comentar a linha abaixo quando não for a primeira vez rodando o código para esse vídeo\n",
        "  predictions_json = df_and_json[1]\n",
        "  crop_all_images(X_folder_path, predictions_json)\n",
        "  temperatures = segment_eyes_and_get_temperatures(frames_folder_path, X_folder_path, y_folder_path, model_head_path, model_eyes_path)\n",
        "  return temperatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "i-rTNtbEFKrb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "yRyPtWtoEGEJ",
        "outputId": "3ca18a5c-8941-444c-d468-4c1e87c61200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://ec3bd53081cebea59a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://ec3bd53081cebea59a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Create Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=final_function,\n",
        "    inputs=gr.Textbox(label=\"Enter the video path\"),\n",
        "    outputs=gr.Textbox(label=\"Lista de temperaturas\")\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
